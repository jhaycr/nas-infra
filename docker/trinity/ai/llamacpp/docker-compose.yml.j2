services:
  llama:
    image: ghcr.io/ggml-org/llama.cpp:full
    container_name: llammacpp
    restart: unless-stopped
    volumes:
      - {{ docker_appdata_path }}/llamacpp/models:/models
    ports:
      - target: 8080
        published: 8080
        mode: host